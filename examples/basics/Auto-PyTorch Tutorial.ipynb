{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial introduces the basic Auto-PyTorch API together with the classes for featurized and image data.\n",
    "So far, Auto-PyTorch covers classification and regression on featurized data as well as classification on image data.\n",
    "For installing Auto-PyTorch, please refer to the github page.\n",
    "\n",
    "**Disclaimer**: In this notebook, data will be downloaded from the openml project for featurized tasks and CIFAR10 will be downloaded for image classification. Hence, an internet connection is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "There are classes for featurized tasks (classification, multi-label classification, regression) and image tasks (classification). You can import them via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/mikel/Desktop/Work/Auto-PyTorch/examples/basics\n['/home/mikel/Desktop/Work/Auto-PyTorch', '/home/mikel/.ipython', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/IPython/extensions', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages', '', '/home/mikel/miniconda3/lib/python3.7/lib-dynload', '/home/mikel/miniconda3/lib/python3.7', '/home/mikel/miniconda3/lib/python37.zip', '/home/mikel/bin/caffe/cvpr16-deepbit-master/python', '/home/mikel/Desktop/Work/Auto-PyTorch/examples/basics', '/home/mikel/Desktop/Work/Auto-PyTorch', '/home/mikel/Desktop/Work/Auto-PyTorch/examples/basics', '/tmp/846fd34b-33e9-4e2b-94ee-cf32113786fa', '/home/mikel/bin/caffe/cvpr16-deepbit-master/python', '/home/mikel/.vscode/extensions/ms-python.python-2020.6.90262/pythonFiles', '/home/mikel/.vscode/extensions/ms-python.python-2020.6.90262/pythonFiles/lib/python', '/home/mikel/miniconda3/lib/python37.zip', '/home/mikel/miniconda3/lib/python3.7', '/home/mikel/miniconda3/lib/python3.7/lib-dynload', '', '/home/mikel/.local/lib/python3.7/site-packages', '/home/mikel/Desktop/Computer Science Master/LAB/AutoML/NASLib', '/home/mikel/.local/lib/python3.7/site-packages/numpy-1.16.4-py3.7-linux-x86_64.egg', '/home/mikel/.local/lib/python3.7/site-packages/tqdm-4.46.0-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/networkx-2.4-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/nas_bench_201-1.3-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/PyYAML-5.3.1-py3.7-linux-x86_64.egg', '/home/mikel/.local/lib/python3.7/site-packages/hyperopt-0.1.2-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/Cython-3.0a5-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/ConfigSpace-0.4.13-py3.7-linux-x86_64.egg', '/home/mikel/.local/lib/python3.7/site-packages/decorator-4.4.2-py3.7.egg', '/home/mikel/.local/lib/python3.7/site-packages/pymongo-3.10.1-py3.7-linux-x86_64.egg', '/home/mikel/miniconda3/lib/python3.7/site-packages', '/home/mikel/miniconda3/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg', '/home/mikel/miniconda3/lib/python3.7/site-packages/IPython/extensions', '/home/mikel/.ipython']\n"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "path = ['/home/mikel/Desktop/Work/Auto-PyTorch', '/home/mikel/Desktop/Work/Auto-PyTorch/examples/basics', '/home/mikel/bin/caffe/cvpr16-deepbit-master/python', '/home/mikel/miniconda3/lib/python37.zip', '/home/mikel/miniconda3/lib/python3.7', '/home/mikel/miniconda3/lib/python3.7/lib-dynload', '', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/autoPyTorch-0.0.2-py3.7.egg', '/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/IPython/extensions', '/home/mikel/.ipython']\n",
    "for ele in path:\n",
    "    sys.path.insert(0, ele)\n",
    "\n",
    "import os\n",
    "sys.path.insert(0,\"/home/mikel/Desktop/Work/Auto-PyTorch\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Editing!\n"
    }
   ],
   "source": [
    "from autoPyTorch import (AutoNetClassification,\n",
    "                         AutoNetMultilabel,\n",
    "                         AutoNetRegression,\n",
    "                         AutoNetImageClassification,\n",
    "                         AutoNetImageClassificationMultipleDatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports for later usage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import openml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon initialization of a class, you can specify its configuration. Later, you can override its configuration in each fit call. The *config_preset* allows to constrain the search space to one of *tiny_cs, medium_cs* or *full_cs*. These presets can be seen in *core/presets/*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autonet = AutoNetClassification(config_preset=\"tiny_cs\", result_logger_dir=\"logs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some useful methods provided by the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the current configuration as dict\n",
    "current_configuration = autonet.get_current_autonet_config()\n",
    "\n",
    "# Get the ConfigSpace object with all hyperparameters, conditions, default values and default ranges\n",
    "hyperparameter_search_space = autonet.get_hyperparameter_search_space()\n",
    "\n",
    "# Print all possible configuration options \n",
    "#autonet.print_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The most important methods for using Auto-PyTorch are ***fit***, ***refit***, ***score*** and ***predict***.\n",
    "\n",
    "First, we get some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get data from the openml task \"Supervised Classification on credit-g (https://www.openml.org/t/31)\"\n",
    "task = openml.tasks.get_task(task_id=31)\n",
    "X, y = task.get_X_and_y()\n",
    "ind_train, ind_test = task.get_train_test_split_indices()\n",
    "X_train, Y_train = X[ind_train], y[ind_train]\n",
    "X_test, Y_test = X[ind_test], y[ind_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***fit*** is used to search for a good configuration by fitting configurations chosen by the algorithm (by default BOHB). The incumbent configuration is then returned and stored in the class.\n",
    "\n",
    "We recommend to have a look at the possible configuration options first. Some of the most important options allow you to set the budget type (epochs or time), run id and task id for cluster usage, tensorboard logging, seed and more.\n",
    "\n",
    "Here we search for a configuration for 300 seconds with 60-100 s time for fitting each individual configuration.\n",
    "Use the *validation_split* parameter to specify a split size. You can also pass your own validation set\n",
    "via *X_val* and *Y_val*. Use *log_level=\"info\"* or *log_level=\"debug\"* for more detailed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\ndata saved in: logs/Train/\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker.py\", line 119, in optimize_pipeline\n    refit=False, rescore=False, hyperparameter_config_id=config_id, dataset_info=self.dataset_info)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n    return self.root.fit_traverse(**kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n    node.fit_output = node.fit(**required_kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/cross_validation.py\", line 109, in fit\n    result = self.sub_pipeline.fit_pipeline(X=X, Y=Y, **sub_pipeline_kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n    return self.root.fit_traverse(**kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n    node.fit_output = node.fit(**required_kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/train_node.py\", line 111, in fit\n    optimize_metric_results, train_loss, stop_training = trainer.train(epoch + 1, train_loader)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/components/training/trainer.py\", line 110, in train\n    data = data.to(self.device)\nKeyboardInterrupt\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-db95d06aef4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           \u001b[0mmin_budget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0mmax_budget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                           refit=True)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save fit results as json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/api.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, X_valid, Y_valid, refit, **autonet_config)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         self.fit_result = self.pipeline.fit_pipeline(pipeline_config=self.autonet_config,\n\u001b[0;32m--> 144\u001b[0;31m                                                      X_train=X_train, Y_train=Y_train, X_valid=X_valid, Y_valid=Y_valid)\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCreateDatasetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\u001b[0m in \u001b[0;36mfit_pipeline\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_traverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\u001b[0m in \u001b[0;36mfit_traverse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# call fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequired_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Node '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' does not return a dictionary.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/optimization_algorithm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, pipeline_config, X_train, Y_train, X_valid, Y_valid, result_loggers, dataset_info, shutdownables, refit)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 self.run_optimization_algorithm(pipeline_config=pipeline_config, run_id=run_id, ns_host=ns_host,\n\u001b[1;32m    129\u001b[0m                     \u001b[0mns_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnameserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_loggers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_loggers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     dataset_info=dataset_info, logger=logger)\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/optimization_algorithm.py\u001b[0m in \u001b[0;36mrun_optimization_algorithm\u001b[0;34m(self, pipeline_config, run_id, ns_host, ns_port, nameserver, task_id, result_loggers, dataset_info, logger)\u001b[0m\n\u001b[1;32m    397\u001b[0m         HB.run_until(runtime=(pipeline_config[\"max_runtime\"] - reduce_runtime),\n\u001b[1;32m    398\u001b[0m                      \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_iterations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                      min_n_workers=min_num_workers)\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mHB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshutdown_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/hpbandster_extensions/bohb_ext.py\u001b[0m in \u001b[0;36mrun_until\u001b[0;34m(self, runtime, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mminimum\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mstarting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_with_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_n_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/hpbandster_extensions/run_with_time.py\u001b[0m in \u001b[0;36mrun_with_time\u001b[0;34m(self, runtime, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Check if timelimit is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/master.py\u001b[0m in \u001b[0;36m_queue_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HBMASTER: running jobs: %i, queue sizes: %s -> wait'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_submit_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autonet = AutoNetClassification(config_preset=\"tiny_cs\", result_logger_dir=\"logs/\", use_tensorboard_logger=True)\n",
    "# Fit (note that the settings are for demonstration, you might need larger budgets)\n",
    "results_fit = autonet.fit(X_train=X_train,\n",
    "                          Y_train=Y_train,\n",
    "                          validation_split=0.3,\n",
    "                          max_runtime=300,\n",
    "                          min_budget=60,\n",
    "                          max_budget=100,\n",
    "                          refit=True)\n",
    "\n",
    "# Save fit results as json\n",
    "with open(\"logs/results_fit.json\", \"w\") as file:\n",
    "    json.dump(results_fit, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***refit*** allows you to fit a configuration of your choice for a defined time. By default, the incumbent configuration is refitted during a *fit* call using the *max_budget*. However, *refit* might be useful if you want to fit on the full dataset or even another dataset or if you just want to fit a model without searching.\n",
    "\n",
    "You can specify a hyperparameter configuration to fit (if you do not specify a configuration the incumbent configuration from the last fit call will be used):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "09:14:53 Start autonet with config:\n{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing', 'plateau'], 'networks': ['shapedresnet'], 'over_sampling_methods': ['smote'], 'preprocessors': ['none', 'truncated_svd', 'power_transformer'], 'target_size_strategies': ['none', 'upsample', 'median'], 'result_logger_dir': 'logs/', 'budget_type': 'epochs', 'log_level': 'info', 'use_tensorboard_logger': True, 'validation_split': 0.0, 'hyperparameter_search_space_updates': None, 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': 'wlp3s0', 'memory_limit_mb': 1000000, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'cross_validator': 'none', 'cross_validator_args': {}, 'min_budget_for_cv': 0, 'shuffle': True, 'imputation_strategies': ['mean', 'median', 'most_frequent'], 'normalization_strategies': ['none', 'minmax', 'standardize', 'maxabs'], 'under_sampling_methods': ['none', 'random'], 'final_activation': 'softmax', 'initialization_methods': ['default', 'sparse'], 'initializer': 'simple_initializer', 'optimizer': ['adam', 'adamw', 'sgd', 'rmsprop'], 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'loss_modules': ['cross_entropy', 'cross_entropy_weighted'], 'batch_loss_computation_techniques': ['standard', 'mixup'], 'cuda': True, 'torch_num_threads': 1, 'full_eval_each_epoch': False, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'random_seed': 2033034208, 'min_budget': 5, 'max_budget': 150, 'max_runtime': inf, 'num_iterations': 4, 'cv_splits': 1, 'increase_number_of_trained_datasets': False}\n09:14:53 Start Refitting\n09:14:54 [AutoNet] No validation set given and either no cross validator given or budget too low for CV. Continue by splitting 0 of training data.\n09:14:54 [AutoNet] CV split 0 of 1\n09:15:01 Finished train with budget 50.0: Preprocessing took 2s, Training took 4s, Wrap up took 0s. Total time consumption in s: 7\n09:15:01 [AutoNet] Done with current split!\n09:15:01 Aggregate the results across the splits\n09:15:01 Process 1 additional result(s)\n09:15:01 Done Refitting\n"
    }
   ],
   "source": [
    "# Create an autonet\n",
    "autonet_config = {\n",
    "    \"result_logger_dir\" : \"logs/\",\n",
    "    \"budget_type\" : \"epochs\",\n",
    "    \"log_level\" : \"info\", \n",
    "    \"use_tensorboard_logger\" : True,\n",
    "    \"validation_split\" : 0.0\n",
    "    }\n",
    "autonet = AutoNetClassification(**autonet_config)\n",
    "\n",
    "# Sample a random hyperparameter configuration as an example\n",
    "hyperparameter_config = autonet.get_hyperparameter_search_space().sample_configuration().get_dictionary()\n",
    "\n",
    "# Refit with sampled hyperparameter config for 120 s. This time on the full dataset.\n",
    "results_refit = autonet.refit(X_train=X_train,\n",
    "                              Y_train=Y_train,\n",
    "                              X_valid=None,\n",
    "                              Y_valid=None,\n",
    "                              hyperparameter_config=hyperparameter_config,\n",
    "                              autonet_config=autonet.get_current_autonet_config(),\n",
    "                              budget=50)\n",
    "\n",
    "# Save json\n",
    "with open(\"logs/results_refit.json\", \"w\") as file:\n",
    "    json.dump(results_refit, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***pred*** returns the predictions of the incumbent model. ***score*** can be used to evaluate the model on a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model prediction: [[0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]]\nAccuracy score 70.0\n"
    }
   ],
   "source": [
    "# See how the random configuration performs (often it just predicts 0)\n",
    "score = autonet.score(X_test=X_test, Y_test=Y_test)\n",
    "pred = autonet.predict(X=X_test)\n",
    "\n",
    "print(\"Model prediction:\", pred[0:10])\n",
    "print(\"Accuracy score\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also get the incumbent model as PyTorch Sequential model via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Linear(in_features=19, out_features=187, bias=True)\n  (1): Sequential(\n    (0): ResBlock(\n      (shortcut): Linear(in_features=187, out_features=135, bias=True)\n      (start_norm): Sequential(\n        (0): BatchNorm1d(187, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n      )\n      (layers): Sequential(\n        (0): Linear(in_features=187, out_features=135, bias=True)\n        (1): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=135, out_features=135, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): Linear(in_features=187, out_features=135, bias=True)\n        (1): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=135, out_features=135, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n    )\n  )\n  (2): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=135, out_features=135, bias=True)\n        (3): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=135, out_features=135, bias=True)\n      )\n    )\n  )\n  (3): Sequential(\n    (0): ResBlock(\n      (shortcut): Linear(in_features=135, out_features=83, bias=True)\n      (start_norm): Sequential(\n        (0): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n      )\n      (layers): Sequential(\n        (0): Linear(in_features=135, out_features=83, bias=True)\n        (1): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=83, out_features=83, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): Linear(in_features=135, out_features=83, bias=True)\n        (1): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=83, out_features=83, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n    )\n  )\n  (4): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=83, out_features=83, bias=True)\n        (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=83, out_features=83, bias=True)\n      )\n    )\n  )\n  (5): Sequential(\n    (0): ResBlock(\n      (shortcut): Linear(in_features=83, out_features=31, bias=True)\n      (start_norm): Sequential(\n        (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n      )\n      (layers): Sequential(\n        (0): Linear(in_features=83, out_features=31, bias=True)\n        (1): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=31, out_features=31, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): Linear(in_features=83, out_features=31, bias=True)\n        (1): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Tanh()\n        (3): Dropout(p=True, inplace=False)\n        (4): Linear(in_features=31, out_features=31, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n    )\n  )\n  (6): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n      (shake_shake_layers): Sequential(\n        (0): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): Tanh()\n        (2): Linear(in_features=31, out_features=31, bias=True)\n        (3): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): Tanh()\n        (5): Dropout(p=True, inplace=False)\n        (6): Linear(in_features=31, out_features=31, bias=True)\n      )\n    )\n  )\n  (7): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (8): Tanh()\n  (9): Linear(in_features=31, out_features=2, bias=True)\n)\n"
    }
   ],
   "source": [
    "pytorch_model = autonet.get_pytorch_model()\n",
    "print(pytorch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurized Data\n",
    "\n",
    "All classes for featurized data (*AutoNetClassification*, *AutoNetMultilabel*, *AutoNetRegression*) can be used as in the example above. The only difference is the type of labels they accept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data\n",
    "\n",
    "Auto-PyTorch provides two classes for image data. *autonet_image_classification* can be used for classification for images. The *autonet_multi_image_classification* class allows to search for configurations for image classification across multiple datasets. This means Auto-PyTorch will try to choose a configuration that works well on all given datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes\n",
    "autonet_image_classification = AutoNetImageClassification(config_preset=\"full_cs\", result_logger_dir=\"logs/\",use_tensorboard_logger=True, tensorboard_min_log_interval=1)\n",
    "#autonet_multi_image_classification = AutoNetImageClassificationMultipleDatasets(config_preset=\"tiny_cs\", result_logger_dir=\"logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For passing your image data, you have two options (note that arrays are expected):\n",
    "\n",
    "I) Via a path to a comma-separated value file, which in turn contains the paths to the images and the image labels (note header is assumed to be None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.abspath(\"../../datasets/example.csv\")\n",
    "\n",
    "X_train = np.array([csv_dir])\n",
    "Y_train = np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II) directly passing the paths to the images and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_dir, header=None)\n",
    "X_train = df.values[:,0]\n",
    "Y_train = df.values[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Make sure you specify *image_root_folders* if the paths to the images are not specified from your current working directory. You can also specify *images_shape* to up- or downscale images.\n",
    "\n",
    "Using the flag *save_checkpoints=True* will save checkpoints to the result directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "m.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:06 job (300, 1, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.05415678024291992 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:07 job (301, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.07382583618164062 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:09 job (301, 0, 1) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.057023048400878906 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:11 job (302, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.04853343963623047 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:13 job (302, 0, 1) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.04869532585144043 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:15 job (302, 0, 2) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.052707672119140625 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:15 job (302, 1, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.06623315811157227 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:17 job (303, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.05440640449523926 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:18 job (303, 0, 1) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.03877663612365723 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:18 job (304, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.04485130310058594 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:20 job (304, 0, 1) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.04864859580993652 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:22 job (304, 0, 2) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.054904937744140625 seconds with budget 200.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:22 job (304, 1, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.04513287544250488 seconds with budget 600.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 110, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n11:54:24 job (305, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 71, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.038465261459350586 seconds with budget 600.0\n\nlist index out of range\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/image/optimization_algorithm_no_timelimit.py\", line 126, in fit\n    res = self.parse_results(pipeline_config[\"result_logger_dir\"])\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/image/optimization_algorithm_no_timelimit.py\", line 235, in parse_results\n    incumbent_trajectory = res.get_incumbent_trajectory(bigger_is_better=False, non_decreasing_budget=False)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/result.py\", line 310, in get_incumbent_trajectory\n    return_dict['config_ids'].append(return_dict['config_ids'][-1])\nIndexError: list index out of range\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "No models fit during training, please retry with a larger max_runtime.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7405a42d2716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                  \u001b[0mmax_runtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                  \u001b[0msave_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                  images_root_folders=[os.path.abspath(\"../../datasets/example_images\")])\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/api.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, X_valid, Y_valid, refit, **autonet_config)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"optimized_hyperparameter_config\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimized_hyperparameter_config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# MODIFY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No models fit during training, please retry with a larger max_runtime.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No models fit during training, please retry with a larger max_runtime."
     ]
    }
   ],
   "source": [
    "autonet_image_classification.fit(X_train=X_train,\n",
    "                                 Y_train=Y_train,\n",
    "                                 images_shape=[3,32,32],\n",
    "                                 min_budget=200,\n",
    "                                 max_budget=600,\n",
    "                                 max_runtime=10000,\n",
    "                                 save_checkpoints=True,\n",
    "                                 images_root_folders=[os.path.abspath(\"../../datasets/example_images\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-PyTorch also supports some common datasets. By passing a comma-separated value file with just one line, e.g. \"CIFAR10, 0\" and specifying *default_dataset_download_dir* it will automatically download the data and use it for searching. Supported datasets are CIFAR10, CIFAR100, SVHN and MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "rain pipeline. Took 0.06778836250305176 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:47 job (220, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.09281539916992188 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:47 job (221, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.06446647644042969 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:47 job (222, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.08348226547241211 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:48 job (223, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.125962495803833 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:48 job (224, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.07657456398010254 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:48 job (225, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.07344365119934082 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:49 job (226, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.07285642623901367 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:49 job (227, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.0847177505493164 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:49 job (228, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.09229230880737305 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:50 job (229, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.10101437568664551 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:50 job (230, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.0800631046295166 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:50 job (231, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.061965227127075195 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:51 job (232, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.08049464225769043 seconds with budget 900.0\n\nProcess pynisher function call:\nTraceback (most recent call last):\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/mikel/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n    return_value = ((func(*args, **kwargs), 0))\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 108, in optimize_pipeline\n    random.setstate(random_state)\n  File \"/home/mikel/miniconda3/lib/python3.7/random.py\", line 135, in setstate\n    version = state[0]\nTypeError: 'float' object is not subscriptable\n10:39:51 job (233, 0, 0) failed with exception\nTraceback (most recent call last):\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n    result = {'result': self.compute(*args, config_id=id, **kwargs),\n  File \"/home/mikel/Desktop/Work/Auto-PyTorch/autoPyTorch/core/worker_no_timelimit.py\", line 69, in compute\n    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\nException: Exception in train pipeline. Took 0.07227110862731934 seconds with budget 900.0\n\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2104f7e015dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                  \u001b[0mmax_runtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                  \u001b[0mdefault_dataset_download_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./datasets\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                  images_root_folders=[\"./datasets\"])\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/api.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, X_valid, Y_valid, refit, **autonet_config)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         self.fit_result = self.pipeline.fit_pipeline(pipeline_config=self.autonet_config,\n\u001b[0;32m--> 144\u001b[0;31m                                                      X_train=X_train, Y_train=Y_train, X_valid=X_valid, Y_valid=Y_valid)\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCreateDatasetInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\u001b[0m in \u001b[0;36mfit_pipeline\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_traverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\u001b[0m in \u001b[0;36mfit_traverse\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# call fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequired_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Node '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' does not return a dictionary.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/image/optimization_algorithm_no_timelimit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, pipeline_config, X_train, Y_train, X_valid, Y_valid, refit)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# start BOHB if not on cluster or on master node in cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtask_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result_logger_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/pipeline/nodes/image/optimization_algorithm_no_timelimit.py\u001b[0m in \u001b[0;36mrun_optimization_algorithm\u001b[0;34m(self, pipeline_config, config_space, constant_hyperparameter, run_id, ns_host, ns_port, nameserver, task_id)\u001b[0m\n\u001b[1;32m    289\u001b[0m         HB.run_until(runtime=(pipeline_config[\"max_runtime\"] - reduce_runtime),\n\u001b[1;32m    290\u001b[0m                      \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_iterations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                      min_n_workers=min_num_workers)\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mHB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshutdown_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/hpbandster_extensions/bohb_ext.py\u001b[0m in \u001b[0;36mrun_until\u001b[0;34m(self, runtime, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mminimum\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mstarting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_with_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_n_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/autoPyTorch/core/hpbandster_extensions/run_with_time.py\u001b[0m in \u001b[0;36mrun_with_time\u001b[0;34m(self, runtime, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Check if timelimit is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/Auto-PyTorch/env/lib/python3.7/site-packages/hpbandster/core/master.py\u001b[0m in \u001b[0;36m_queue_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HBMASTER: running jobs: %i, queue sizes: %s -> wait'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_submit_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_cifar_csv = os.path.abspath(\"../../datasets/CIFAR10.csv\")\n",
    "\n",
    "autonet_image_classification.fit(X_train=np.array([path_to_cifar_csv]),\n",
    "                                 Y_train=np.array([0]),\n",
    "                                 min_budget=600,\n",
    "                                 max_budget=900,\n",
    "                                 max_runtime=600,\n",
    "                                 default_dataset_download_dir=\"./datasets\",\n",
    "                                 images_root_folders=[\"./datasets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For searching across multiple datasets, pass multiple csv files to the corresponding Auto-PyTorch class. Make sure your specify *images_root_folders* for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autonet_multi_image_classification.fit(X_train=np.array([path_to_cifar_csv, csv_dir]),\n",
    "                                       Y_train=np.array([0]),\n",
    "                                       min_budget=1500,\n",
    "                                       max_budget=2000,\n",
    "                                       max_runtime=4000,\n",
    "                                       default_dataset_download_dir=\"./datasets\",\n",
    "                                       images_root_folders=[\"./datasets\", \"./datasets/example_images\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}